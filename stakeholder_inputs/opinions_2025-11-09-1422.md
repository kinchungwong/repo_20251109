# Calibrating Process Rigor for Spec-Driven Development with AI Agents

## Context
- Source: Review of short-term memory file `repo_20251109/.specify/short-term-memory/todo-constitution-revision-2025-11-09_1223.md`.
- Note: The referenced file `todo-obsolete-constitution-lessons-2025-11-09_1240.md` was not found in the repository.

## Key Lessons from Short-Term Memory Review
- Prior constitutions and checklists produced “process fatigue” by forcing exhaustive reasoning that overflowed AI context; future guidance should emphasize outcome-focused checkpoints instead of rigid step-by-step mandates.
- Governance must scale with risk: heavier gates for safety-critical runtime work, lighter touch for routine or low-risk tasks, and clear escalation paths when automation is blocked.
- Delivery artifacts should remain minimal yet enforceable—plans, specs, and evidence bundles should exist, but agents need pragmatic exemptions to avoid unnecessary context load.

## Guidance on Calibrating Methodology for SDD and Agent-Based Development
### 1. Anchor Rules to Risk and Impact
- Classify work into risk tiers (e.g., runtime core, feature enhancements, maintenance). Assign only the process controls that mitigate the real risks of each tier: full verification and evidence logging for high-risk changes; lightweight specs and peer review for low-risk tasks. This reflects the “risk-based governance” takeaway and keeps agents from re-evaluating the entire rulebook for every change.
- Use checklists as modular bundles tied to these tiers so an agent activates only the relevant subset rather than carrying the full process in context.

### 2. Define Decision Levers Individually
For each potential rule (spec template, testing requirement, approval step), decide:
1. **Purpose** – What failure does the rule prevent?
2. **Trigger Condition** – Which risk tier or artifact type activates it?
3. **Evidence Expectation** – What minimally sufficient proof satisfies the rule?
4. **Automation Support** – Can an agent gather the evidence autonomously? If not, provide escalation or user hand-off instructions as noted in the short-term memory file.

### 3. Guard AI Context Bandwidth
- Favor “outcome contracts” (e.g., “Provide one test demonstrating failure before fix and success after fix”) rather than enumerating every intermediate step.
- Store reusable reference materials (checklist modules, templates) outside the immediate context and link to them. Agents pull in only the relevant fragment, limiting context explosion.
- Encourage agents to summarize evidence instead of duplicating raw logs unless the risk tier demands full output.

### 4. Preserve Agility with Governance Feedback Loops
- Treat constitutions and process guides as living documents: after each cycle, evaluate whether rules genuinely prevented defects or just consumed context. Retire or streamline low-value controls.
- Codify “pragmatic exemption” paths—if following a rule would overflow context or is impossible due to environment limits, allow the agent to document the constraint and proceed with mitigation, echoing the automation limits mentioned in the notes.

### 5. Foster Shared Vocabulary Between Humans and Agents
- Maintain clear definitions (e.g., GSFD Graph/Step/Field/Data semantics) but encourage plain-English restatements so agents do not waste context translating terminology.
- Include concise headers and scoping in documents, enabling agents to target exactly the sections they need.

## Conclusion
Blending risk-tiered governance, modular rule selection, and outcome-focused evidence keeps Spec-Driven Development disciplined without reintroducing the heavy-handed process burden that previously exhausted AI context capacity.
