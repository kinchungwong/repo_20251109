# Stakeholder Opinions (2025-11-09 16:24 PST)

This stakeholder opinion file recommends certain constitution principles and governance details. Stakeholders strongly recommend these considerations.

## Core Principles and Knowledge

### Knowledge 1 - Specification-Driven Development (SDD) via Spec-Kit

- Spec-Kit is both a methodology and an enhancement pack for AI agents by providing a robust set of conventions, governance prompts, templates for specification artifacts, and automation tools.
- SDD encourages human-agent collaboration, with humans providing oversight, validation, Socratic decision-making at key junctures, recovery from mistakes and failures, and performing privileged tasks on behalf of the agent.
- SDD is not a waterfall model; it supports iterative and incremental delivery.
- SDD can be used as a lightweight process.
- The SDD dogma is that: code is the end result of well-defined specification and implementation. The code is not the starting point.
- Project structure and development workflows are enforced by Spec-Kit.
- De-risking iterations are allowed in Spec-Kit. 

<!-- exploratory research and prototyping the lessons are captured and fed back into the specification process. Code artifacts from research/prototyping are moved out of source folders  -->

### Knowledge 2 - Specification Anchors with Lightweight Gates

- Specification Anchors are key artifacts that capture the essence of a feature or user story. They serve as a reference point throughout the development process.
- Lightweight Gates are checkpoints that allow for quick validation of assumptions and designs before proceeding to implementation.
- Together, Specification Anchors and Lightweight Gates help ensure that development remains aligned with user needs and business goals.

### Principle 3a - Respect for Agents and their Limitations

- Agents have limited context windows and reasoning capabilities.
- Agents must use short-term-memory notes to capture reasoning trails, dead-ends, and lessons learned, to ensure continuity across interruptions.
- Agents must summarize large artifacts into concise digests when needed, to stay within context limits.
- Agents must not fabricate command outputs or make assumptions about execution results.
- For all multi-step changes on specification artifacts, agents must obey the Agent Document Management Standards (ADMS) found in `.specify/memory/agent_doc_mgmt_stds.md`.

### Principle 3b - Human-Agent Planning, Collaboration, Escalation

- Agents must request human execution of commands when they cannot run them directly, and humans must provide real logs or artifacts as evidence.
- Humans may ask or be asked to collaborate with agents on complex tasks, in myriad ways, including:
  - Socratic questioning to guide agent reasoning, or for the agent to lead and guide human reasoning.
  - Reviewing and validating agent-generated artifacts, in fast and slow ways.
  - Human performing privileged operations on behalf of the agent.
- Be forewarned that complex tasks may encounter many interruptions, detours, failures, and walkbacks.
  - Humans and agents must be patient and persistent.
  - Agents must use short-term-memory notes to capture reasoning trails, dead-ends, and lessons learned, to ensure continuity across interruptions.
- Agents must watch out for automation gaps, and flag them as risks.
  - This project use a technology stack that is not fully automatable.
  - Automate ruthlessly, but do not expect all tasks to be fully automatable.

### Principle 4 - SDD is Iterative, Incremental, and Git-centric

- Each project increment must follow a Specify -> Plan -> Task -> Implement cycle, as enforced by Spec-Kit.
- Each project increment is a Git feature branch, as enforced by Spec-Kit.
- Pull-requests and branch merges represent successful delivery of project increments. These actions are performed by humans on GitHub, not agents.

### Principle 3 - Specification-First Delivery

- Each project increment is a Git feature branch, with its own set of specification artifacts under `/specs/[###-feature-name]/`.
  - Agent must not create these directories themselves; human must create them using Spec-Kit commands.
  - The minimum required artifacts are: `spec.md`, `plan.md`, and `tasks.md`, as enforced by Spec-Kit.
  - Some optional artifacts include: `checklists/`, `data-models/`, and `notes/`.
    - Deeply technical features may contain a `notes/lectures/` folder to remedy knowledge gaps in AI agents.
    - Research spikes may contain a `notes/research/` folder to capture attempts and findings.
  - Additional artifacts may be required depending on the feature type and risk tier; see Appendix 999.
- Each project increment must deliver value, and be independently testable and reviewable.
- Unlike widely-adopted agile methodologies, Spec-Kit does not equate project increments with user stories.
- Project-level user stories span across project increments (branches).
- Project increments may implement multiple user stories, or parts of user stories, or no user stories at all (e.g., research spikes, infrastructure work, bug fixes).
  - Nevertheless, these must be captured and cross-referenced in the specification artifacts.
- All product increments MUST start from an approved `/specs/.../spec.md` that captures prioritized user journeys, acceptance criteria, and edge cases before any research or planning begins.
  - Acceptance criteria MUST always be present, and be testable and measurable.
  - During specification, the human and the agent negotiates and agrees on user journeys and edge cases; some product increments may waive these or impose additional requirements.
- Implementation plans MUST trace every commitment back to the specification and MAY NOT introduce scope that lacks explicit specification coverage.
- Task breakdowns MUST reference the user stories they support so changes remain traceable from specification through delivery.

### Appendix 999 - Feature Types and Risk Tiers

These are the currently known feature (product increment) types:

- User Story
- Research Spike
- Infrastructure Work
- Bug Fix
- Enablement

These are the currently known risk tiers and corresponding policies:

- *This list is still pending.*


-----------------------------------------------------------------------------

<!-- JUNK -->

<!--
Sync Impact Report
- Version change: 1.1.0 → 1.2.0
- Modified principles:
  - III. Test-Led Implementation (clarified reliance on real execution evidence)
- Added sections:
  - VI. Verified Execution Evidence
- Removed sections:
  - None
- Templates requiring updates:
  - ✅ .specify/templates/plan-template.md
  - ✅ .specify/templates/spec-template.md
  - ✅ .specify/templates/tasks-template.md
- Follow-up TODOs:
  - None
-->
# SpecDD Reference Project Constitution

## Core Principles

### I. Specification-First Delivery
- All product increments MUST start from an approved `/specs/.../spec.md` that captures prioritized user journeys, acceptance criteria, and edge cases before any research or planning begins.
- Implementation plans MUST trace every commitment back to the specification and MAY NOT introduce scope that lacks explicit specification coverage.
- Task breakdowns MUST reference the user stories they support so changes remain traceable from specification through delivery.
Rationale: Shared specifications keep delivery anchored to user value and make compliance reviews objective.

### II. Plan-Gated Execution
- Phase 0 and Phase 1 artifacts (`research.md`, `data-model.md`, `quickstart.md`, `contracts/`) MUST be produced and linked in `plan.md` before `/speckit.tasks` or implementation work can start.
- Every `plan.md` MUST include a Constitution Check section that documents how the feature will satisfy each principle before implementation begins.
- Foundational work MUST record gating dependencies; no user story work may begin until the plan documents that prerequisites are complete.
Rationale: Formal gates prevent ad-hoc execution and surface risks before code is written.

### III. Test-Led Implementation (NON-NEGOTIABLE)
- Tests for each user story MUST be defined, committed, and failing before implementation work on that story starts; no code path may be authored without a corresponding red test.
- Every story MUST record a multi-layer test matrix in `tasks.md` covering contract, unit, integration, and—because this project delivers a reusable C++ task-graph runtime—concurrency probes, determinism checks, stress/performance benchmarks, and sanitizer/fuzz harnesses needed to prove the runtime safe on real hardware.
- Test artifacts MUST encode the invariants promised in `spec.md` (single-writer enforcement, sealed snapshot semantics, fixed worker-pool behavior, edge-case handling) and include reproduction instructions for CI rigs meeting the documented hardware requirements.
- Continuous integration MUST block merges when required tests are absent, failing, or do not exercise the declared invariants; stories close only after all planned tests pass under the mandated tooling (sanitizers, profilers, perf harnesses) with real execution traces or logs attached to the artifact history—simulated outputs are not acceptable evidence.
Rationale: C++17 lacks built-in task-graph safety guarantees; test-led proofs of concurrency correctness and performance are the only objective evidence that this reusable library behaves safely for downstream workloads.

### IV. Independent Story Slices
- User stories in `spec.md` MUST be framed so each delivers a demonstrable outcome without relying on future stories.
- Task lists MUST keep work for different stories isolated (use `[P]` only when there is no shared file conflict) and document unavoidable cross-story dependencies in the Complexity Tracking table.
- Deployment and review MUST evaluate each story as an independently releasable increment before progressing to the next story.
Rationale: Independence enables incremental value delivery and reduces coordination risk.

### V. Living Artifact Stewardship
- Canonical artifacts (spec, plan, research, data-model, quickstart, contracts, tasks, and aggregated agent guidance) MUST be updated immediately when decisions change scope, design, or constraints.
- Observability, performance, and compliance requirements MUST be documented in an artifact before code changes that implement them.
- Upon feature completion, the agent guidance file MUST be regenerated or manually updated so automation reflects the current system state.
Rationale: Up-to-date artifacts keep automated tooling reliable and preserve institutional knowledge.

### VI. Verified Execution Evidence
- Agents MUST never treat simulated or hypothesized command output (e.g., fake `cmake`, compiler, or test results) as factual. When a command cannot be run directly, they MUST request that the user execute it and provide the real logs or artifacts before relying on the outcome.
- Build, test, and benchmark steps recorded in specs, plans, or tasks MUST reference the actual command invocation plus the source of truth for its output (log path, attachment, or checklist link). When automation is impossible, the artifact MUST state who supplied the evidence and when.
- Reviewers MUST reject any change whose validation relies on simulated output or “assumed pass” language; all assertions about runtime behavior require reproducible, real execution evidence captured in the repository’s reports or notes.
Rationale: Preventing trust in hallucinated outputs preserves the integrity of safety-critical concurrency work and keeps audits defensible.

## Required Delivery Artifacts

The following artifacts are mandatory for every feature and MUST live under `/specs/[###-feature-name]/` unless otherwise stated:

- `spec.md`: Prioritized, independently testable user stories with acceptance scenarios and edge cases (Principles I & IV).
- `plan.md`: Constitution Check, technical context, and agreed structure mapping artifacts to implementation phases (Principles I & II).
- `research.md`, `data-model.md`, `quickstart.md`, `contracts/`: Document Phase 0/1 findings, domain models, onboarding steps, and external agreements before coding (Principle II).
- `tasks.md`: Story-organized task list including tests, dependencies, and Complexity Tracking justifications (Principles III & IV).
- Repository-level guidance (`.specify/templates/*`, agent file) and runtime notes: update alongside changes so later features inherit accurate constraints (Principle V).

## Delivery Workflow

1. Author and approve `spec.md`, ensuring stories are independent, prioritized, and testable.
2. Produce Phase 0/1 artifacts and complete `plan.md`, explicitly documenting Constitution Check outcomes and gating prerequisites.
3. Generate `tasks.md` only after the plan is ratified; enumerate tests first, then implementation work per story.
4. Execute per story: write failing tests, implement to pass, validate independence, and update artifacts before closing the story.
5. Regenerate or update aggregated guidance and verify all artifacts remain in sync prior to declaring the feature complete.

## Governance

- This constitution supersedes conflicting process documentation; subordinate templates must be updated to align rather than override these rules.
- Amendment proposals MUST document the intended semantic version bump (MAJOR for principle removal/redefinition, MINOR for new principles or material scope, PATCH for clarifications) before review.
- Adopt amendments via pull request that includes an updated Sync Impact Report, constitution text, and any necessary template updates; ratification requires maintainer approval and recorded decision history.
- Each `/speckit.plan` run MUST include a Constitution Check audit referencing the principles; features failing the gate cannot progress until the gap is resolved.
- Conduct a quarterly compliance review (or before major releases) to confirm artifacts, tests, and automation still reflect the constitution; corrective work MUST be scheduled when gaps are found.

**Version**: 1.2.0 | **Ratified**: 2025-11-05 | **Last Amended**: 2025-11-07



-----------------------------------------------------------------------------

<!-- JUNK -->

<!-- Sync Impact Report
Version change: N/A → 0.9.0
Modified principles: Template placeholders → Principle 1–9 (pending wording)
Added sections: Core Principles (pending), Process Guardrails & Risk Tiers (pending), Delivery Workflow & Evidence Handling (pending)
Removed sections: None
Templates requiring updates: ⚠ .specify/templates/plan-template.md, ⚠ .specify/templates/spec-template.md, ⚠ .specify/templates/tasks-template.md, ⚠ .specify/templates/checklist-template.md, ⚠ .specify/templates/agent-file-template.md
Follow-up TODOs: TODO(RATIFICATION_DATE), finalize principle thresholds, define risk-tiered checklists, align templates, confirm gsfd prefix registry entry
-->

# repo_20251109 Constitution
> **Status**: PENDING RATIFICATION — draft captured 2025-11-09 to guide negotiations; do not enforce verbatim yet.

## Core Principles

### Principle 1 – Agent-First Stewardship & Context Protection
> Pending ratification: language will be tuned once stakeholder feedback confirms scope.

AI agents MUST structure every artifact with the mandated headers, concise scope statements, and cross-references so collaborators can reload context quickly. Documents SHALL remain single sources of truth and retire redundant reasoning into `.specify/short-term-memory/` digests once resolved, ensuring large checklists or audits are summarized rather than re-litigated.

### Principle 2 – Specification Anchors with Lightweight Gates
> Pending ratification: balance between thoroughness and agility under review.

Every net-new capability MUST originate from an approved `spec.md` capturing user journeys, acceptance criteria, and edge cases, yet small maintenance or safety fixes MAY follow an expedited path documented in the plan’s Constitution Check. Plans MUST trace deliverables back to specs while explicitly calling out any intentionally deferred requirements.

### Principle 3 – Scaled Agile Flow & Incremental Value
> Pending ratification: needs alignment with stakeholder scaled-agile expectations.

Work MUST be organized into independently deliverable increments with clear priorities (P1/P2/P3) so testing, demos, and evidence gathering can conclude per slice. Program-level ceremonies (backlog sync, system demos) SHALL consume artifact summaries rather than replaying full documents, preserving agent context budget.

### Principle 4 – Deterministic Graph Safety & Terminology Discipline
> Pending ratification: GSFD naming rules subject to refinement.

The constitution recognizes GSFD (Graph, Step, Field, Data) semantics: define/execute phases MUST remain separate, implicit dependencies derive from Data flows, and explicit dependencies are documented where needed. `gsfd` is the approved namespace/prefix for runtime code and include directories, and artifacts MUST explain concept names in plain English before referencing identifiers to avoid cross-POC ambiguity.

### Principle 5 – Safety-Critical Test Harness Discipline
> Pending ratification: risk tiers for the harness to be calibrated.

Core runtime or executor changes MUST ship with multi-layer tests (contract, unit, integration, concurrency stress, sanitizer/fuzz) authored before implementation and executed on real hardware or CI nodes. Lower-risk features MAY tailor the matrix but MUST document the rationale and minimum test evidence retained for audit.

### Principle 6 – Automation Boundaries & Escalation
> Pending ratification: escalation paths awaiting stakeholder confirmation.

Agents SHALL declare tooling or environment limitations upfront, MUST NOT fabricate command output, and MUST either capture real logs or request human execution with attached evidence. Automation gaps require explicit TODOs plus owner assignments in artifacts so nothing silently drops.

### Principle 7 – Verified Execution Evidence
> Pending ratification: evidence catalog format TBD.

All assertions about behavior (builds, tests, benchmarks) MUST cite the exact command, platform, and log location. When evidence cannot reside in-repo (size/security), artifacts MUST link to the authoritative storage path and record who validated the run and when. Simulated or assumed outputs are prohibited.

### Principle 8 – Delivery Artifact Minimums & Single Source of Truth
> Pending ratification: exemptions and tooling hooks still in discussion.

Each feature SHALL maintain a coherent set of artifacts: `spec.md`, `plan.md`, `tasks.md`, and, when applicable, `research.md`, `data-model.md`, `quickstart.md`, and `contracts/`. Updates happen in lockstep with decisions, and `.specify/templates/*` plus the agent guidance file MUST evolve to mirror the latest rules to keep automation honest.

### Principle 9 – Observability, Diagnostics, and Evidence of Performance
> Pending ratification: observability requirements to be prioritized with stakeholders.

Runtime work MUST define the logging, tracing, and metrics needed to debug gsfd graphs (including deterministic replay hooks) before implementation. Performance targets (throughput, latency, memory) SHALL be measurable, and observability scaffolding MUST be part of the acceptance criteria, not an afterthought.

## Process Guardrails & Risk Tiers
> Pending ratification: content captures negotiation baseline, not final policy.

The program SHALL maintain a lightweight risk-tier matrix (e.g., Tier 0 core runtime, Tier 1 feature expansion, Tier 2 maintenance) describing which artifacts, reviews, and harness steps are mandatory. High-tier work triggers full gates (Phase 0/1 artifacts, exhaustive tests, checklist deep-dives); lower tiers MAY opt into abridged flows provided the Constitution Check logs the deviation and rationale. Checklists SHALL be modular per tier to avoid reprocessing irrelevant items.

## Delivery Workflow & Evidence Handling
> Pending ratification: workflow steps may change once governance is settled.

1. Capture or update `spec.md` with agent-friendly structure and register any new cross-reference prefixes.  
2. Draft `plan.md` with Constitution Check focusing on delta analysis rather than rehashing closed findings; identify gating dependencies explicitly.  
3. Generate `tasks.md` after plan approval, grouping by user story and flagging where test-first work applies per risk tier.  
4. Execute increments: author failing tests (per Principle 5), implement features, collect real execution evidence, and store/log results with durable links.  
5. Summarize findings in short-term-memory notes when reasoning exceeds practical artifact scope, then incorporate conclusions into canonical docs and retire the temporary files.  
6. Regenerate or update agent guidance so automation inherits the new rules, ensuring `gsfd` namespace usage and observability requirements propagate.

## Governance
> Pending ratification: governance cadence and approval thresholds under negotiation.

This draft supersedes no prior policy until ratified; however, contributors SHALL begin aligning behavior with its intent to surface gaps early. Amendment proposals MUST include the intended semantic version bump (MAJOR for rewrites/removals, MINOR for new principles/sections, PATCH for clarifications) plus an updated Sync Impact Report and a delta list for affected templates. Reviews SHALL verify that ratified principles cascade into `.specify/templates/*`, `.codex/` prompts, and runtime guidance. Compliance reviews SHALL occur before each quarterly increment or major release to ensure evidence trails remain reproducible and automation guardrails still match reality.

**Version**: 0.9.0 | **Ratified**: TODO(RATIFICATION_DATE): set once stakeholder sign-off occurs | **Last Amended**: 2025-11-09
